\section{Adjoint-Based Method for Error Estimation}
\label{section:Adjoint}
\subsection{Introduction}

In Gradient-based Mesh adaptation techniques, emphasis is placed on the change of values of the Solution variables across cells, and any high rates of change require a mesh refinement suitable enough to capture a smoother transition, e.g. across a shock wave that forms on the upper surface of an airfoil in transonic regime. In this scenario, a quantity such as density or pressure could be monitored.\par
Adjoint-based Error Estimation focuses on the \textit{sensitivities}, whereby some output of interest (henceforth termed as a \textit{functional}), e.g. Lift on an airfoil, is sensitive to the mesh refinement levels upstream of the airfoil along the chord line. The Adjoint approach is a more efficient, albeit expensive, criteria for mesh refinement.\par
Both Adjoint and Gradient-Based approaches apply a \textit{posteriori} technique, in that an initial solution, known as the \textit{Primal solution}, needs to first be evaluated - no refinement criteria can be carried out until some values of the solution are known.\par 
Some of the initial research on Adjoints applied to aerodynamical flows was performed by Giles and Pierce ~\cite{Giles:2000}, Becker and Rannacher ~\cite{Becker:2001} and Venditti and Darmofal ~\cite{Venditti:2001}.


\subsection{Derivation}
If \textbf{R} is the set of all residuals for all cells in the domain, then the systems of equations can be written as:
\begin{equation}
\textbf{R}(\textbf{U}) = 0
\end{equation}
Considering a scalar output of interest \cite{Fidkowski:2013}, say, $J$, we can define it such that:
\begin{equation}
J = J(U)
\end{equation}
where U is a vector containing the solution variable. We define a discrete Adjoint, $\Psi \in \mathbb{R}^N$ as a vector of sensitivities of the output to the $N$ residuals. Each entry of the adjoint essentially tells us the effect that a perturbation in the corresponding entry within the residual vector would have on output $J$. Consider the case fo a residual perturbation due to a change to the input parameter, $\mu$, and $\mu \in \mathbb{R}^{N_p}$. A local sensitivity analysis can be applied as follows:\par
\begin{equation} \label{eqn:chain}
\underbrace{\mu}_{\text{inputs} ~\in~\mathbb{R}^{N_\mu}} ~\to~ \underbrace{\textbf{R}(\textbf{U},\textbf{$\mu$}) = 0}_{\text{\textit{N} equations}} ~ \to ~ \underbrace{\textbf{U}}_{\text{state} ~\in~ \mathbb{R}^N} ~\to~ \underbrace{\text{\textit{J}(\textbf{U})}}_\text{output(scalar)} 
\end{equation}

To monitor the change of $J$ with $\mu$,
\begin{equation}
\frac{dJ}{d\mu} ~\in~ \mathbb{R}^{1~\times~N_{\mu}} = N_\mu ~ \text{sensitivities}
\end{equation}

recalling $\mu \in \mathbb{R}^{N_p}$. If $J$ depended directly on $\mu$ then we would have had $\frac{dJ}{d\mu}$, but in the scenario we consider the case that $J = J(U)$ alone. To evaluate the $N_\mu$ sensitivities we could use: \textit{finite differencing} where the inputs are  perturbed one at a time;  \textit{forward linearization} where the sequence of operations in Equation ~\eqref{eqn:chain} are linearized; and, lastly, the \textit{adjoint approach} which requires an inexpensive residual perturbation calculation, followed by an adjoint weighting to compute the effect on the output:\par
\begin{equation}
\frac{dJ}{d\mu} = \Psi^T ~\frac{\partial R}{\partial \mu}
\end{equation}
One of the key ideas behind the adjoint approach is that the forward problem need be solved only once to evaluate a sensitivity. Given a particular input, $\mu$, we could solve the system to find \textbf{U} such that \textbf{R(U,$\mu$} $ = 0$. Once we perturb $\mu ~\to~ \mu + \delta \mu$, to find the effect on $J$, we would otherwise need to re-solve the discretized system, which would be an expensive step. The Adjoint, on the other hand, precomputes the eddect of \textbf{R} on $J$. The resulting $N$ sensitiviteis are stored in vector $\Psi$.\par

Consider the chain of events in computing sensitivities (i.e. the effects of a small perturbance of the input, $\delta \mu$) via a direct approach:
\begin{enumerate}
\item Input:  $\mu ~\to~ \mu + \delta \mu$
\item Residual: \textbf{R(U, $\mu ~+~ \delta \mu$)} $=$ $\delta$\textbf{R} $\neq 0$ ~$\to$~ \textbf{R(U, $\mu$)} $+$ $\frac{\partial \text{\textbf{R}}}{\partial \mu}$ $\bigg|_{\textbf{U, $\mu$}}$ $\delta \mu = \delta$\textbf{R}
\item State: \textbf{R(U $+ \delta$U, $ \mu + \delta\mu$)} $= ~0$ ~$\to$~ \textbf{R(U, $\mu$)} $+$ $\frac{\partial \text{\textbf{R}}}{\partial \mu}$ $\bigg|_{\textbf{U, $\mu$}}$ $\delta \mu$ $ + \frac{\partial \text{\textbf{R}}}{\partial \text{\textbf{U}}}$     $\bigg|_{\textbf{U, $\mu$}} \delta$U  $ = 0$
\item Output: $J(\textbf{U} + \delta \textbf{U}) = J(\textbf{U}) + \delta J ~\to~ \delta J = \frac{\partial J}{\partial \textbf{U}} \delta U $
\end{enumerate}

Subtracting step 2 from 3:
\begin{equation}
\begin{split}
\frac{\partial \textbf{R}} {\partial \textbf{U}} \bigg|_{\textbf{U, $\mu$}} \delta U &= - \delta R \\
\delta \textbf{U} &= - \left[\frac{\partial \textbf{R}}{\partial \textbf{U}} \right]^{-1} \delta \textbf{R} \\
\end{split}
\end{equation}

We combine this to the output linearization in step 4 to give the output perturbation, $\delta \textbf{U}$ in terms of the residual perturbation, $\delta \textbf{R}$:
\begin{equation}
\begin{split}
\delta J &= \frac{\partial J}{\partial U} \delta \textbf{U} \\
& = \underbrace{\frac{\partial J}{\partial U} \left[\frac{\partial \textbf{R}}{\partial \textbf{U}} \right]^{-1}}_{\Psi^T ~\in~ \mathbb{R}^\textit{N}} \delta \textbf{R}
\end{split}
\end{equation}

The \textit{Adjoint Equation} is then written as:
\begin{equation}
\left( \frac{\partial \textbf{R}}{\partial \textbf{U}} \right) ~\Psi^T~ = \frac{\partial J}{\partial \textbf{U}}
\end{equation}

Once we have $\Psi$, no more solves are required for the system. The calculation of $\frac{\partial \textbf{R}}{\partial \textbf{$\mu$}}$ (henceforth called the \textit{Jacobian}) is much cheaper compared to a forward solve. There are four ways to calculate the adjoint equation within CFFC code:
\begin{itemize}
\item Complexifying Variables - Calculating deriveatives using complex numbers.
\item Finite Differences coupled with Automatic Differentiation Techniques.
\item Analytically - by evaluating the exact Jacobian, and this is an expensive, but very accurate, process.
\item Approximate Jacobian - This will be the starting approach, and then an evaluation will be made on cost and accuracy. A decision will thereafter be made on whether to use the Analytical approach or not. Northrup \cite{Northrup:2013} implemented the script within the CFFC code that builds part of the structure of the Flux Jacobian matrix.
\end{itemize}

\subsection{Solution of Linear Systems}
The Adjoint problem therefore takes the form of a linear system of equations, $Ax=b$, which will be solved utilizing the Trilinos set of packages, written by Sandia National Labs. Trilinos contains very powerful and parallelizable linear algebra solvers. This suite of programs has already been linked to the CFFC code within the SCINET network.

\subsection{Use of Solution Error Estimates in Mesh Adaptation}
The Adjoint solution will indicate areas of higher sensitivity to given changes in input, and this information could indicate a \textit{posteriori} where the mesh would need to be better refined for higher accuracy.

\subsection{Implementing Isotropic Mesh Refinement}
Since the Isotropic Adaptive Mesh Refinement (AMR) is easier as an initial implementation, this will be the first step attempted before applying Anisotropic AMR which further decreases the cell counts, for a comparable level of accuracy that can be achieved by Isotropic AMR.

\subsubsection{Steady Adjoints}

For steady simulations, the solution of the Adjoint is a one time event, and the computational cost is low.

\subsubsection{Unsteady Adjoints}
The Adjoint solution needs to be calculated every single timestep within an unsteady simulation (e.g. for the goal of the project, which is to simulate Turbulent Premixed Flows). This occcurs via running the simulation forward in time while evaluating all the \textit{Primal} solution values at the different time levels until the final timestep, and then marching backwards in time, and solving the Adjoint at each of those timesteps, and re-meshing as required. An error threshold could be defined prior to the process such that arrival of the solution within a favorable regime could indicate to the automated process a suitable end to the refinement cycle.\par
The computational cost for this may likely be very high, and perhaps unattainable for practical purposes.\par


