\section{Introduction and Motivation}

Computational Fluid Dynamics (CFD) has been developed to reduce the time and cost of prototypes in fluid flow experiments. Typical product life-cycles from conception to testing involve numerous design iterations and modifications. From the mid 80s to 90s the stability and reliability of CFD algorithms was improved and CFD's present role has grown to include a vast spectrum of modern day industries. Gordon Moore predicted that computing power would double approximately every two years ~\cite{intel:2005}. Modern day massively-paralleled computer systems have brought computing power to the peta- and exa-scale levels.\par

Real fluid flows almost always involve turbulence, and CFD methods and models have been developed to capture this phenomenon to varying extents of accuracy. Three main approaches exist: Reynolds averaged Navier Stokes (RANS), which uses full modeling of turbulence phenomenon; large eddy simulations (LES) do direct solutions of Turbulence up to some intermediate Taylor scales while modeling the smaller scales; direct numerical simulation (DNS) performs full resolution and calculation of the turbulence without any modelling. Supercomputers have been used within academic and research lab collaborations for the DNS of turbulence in a box such as that by Kaneda and Ishihara ~\cite{kaneda:2006}, but such calculations are limited to low Reynolds numbers and for simple cases. For more complicated analysis, LES is more practical and achievable, such as those involving combustion simulations.\par 

Such a simulation would need to be as accurate as possible. To improve accuracy, so that CFD results can be closer to those from experiment, we need to reduce error. Two  key sources of error within CFD include the discretization of the governing equations (or the general numerical scheme) - which are typically composed in the partial differential equation (PDE) form, and the modeling of the geometry, i.e the mesh resolution. Using high-order discretization schemes and adjoint-based error estimation can prove a more effective way for mesh adaptation since the high-order approach provides an improved accuracy of the solution. Combining this with Adjoint-Based Error Estimation will allow for an optimal technique for mesh refinement. A more common alternative is the gradient (physics) -based approach, but this technique is actually less efficient, in that it requires new sensitivity evaluations for each new parameter of interest. More on gradient-based methods will be discussed in section \ref{section:Adjoint}. \par 